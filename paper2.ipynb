{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A(410)       B(435)       C(460)       D(485)       E(510)   F(535)  \\\n",
      "0   2429.580000  1108.990000  2091.930000   737.330000   835.140000  1376.82   \n",
      "1   1707.900000   725.380000  1974.490000   670.810000   835.930000  1685.28   \n",
      "2   1750.410000  1102.020000  2481.050000   816.800000   960.650000  1741.43   \n",
      "3   2546.680000  1548.400000  2791.560000  1007.160000  1128.000000  1573.73   \n",
      "4   3090.540000  1266.420000  2933.880000   940.610000  1109.840000  2047.64   \n",
      "..          ...          ...          ...          ...          ...      ...   \n",
      "95  2247.430000   833.990000  2195.430000   523.900000   786.990000  1074.36   \n",
      "96  2374.070000   989.420000  2382.530000   567.000000   918.030000  1189.65   \n",
      "97  2318.550000   821.030000  2096.900000   507.260000   781.470000  1070.61   \n",
      "98  3289.170000  1234.540000  3234.430000   873.160000  1112.210000  1742.18   \n",
      "99  2163.039798  1015.779354  2471.640101   744.820303   963.049697      NaN   \n",
      "\n",
      "        G(560)      H(585)       R(610)      I(645)  ...  P   (kg/ha)  \\\n",
      "0   322.870000  318.870000  1305.330000  163.260000  ...        26.10   \n",
      "1   370.310000  373.600000  1335.770000  185.560000  ...        81.99   \n",
      "2   430.510000  437.880000  1206.990000  227.040000  ...        80.59   \n",
      "3   488.660000  499.630000  1338.110000  261.840000  ...        33.81   \n",
      "4   500.910000  512.700000  1482.110000  267.190000  ...        38.19   \n",
      "..         ...         ...          ...         ...  ...          ...   \n",
      "95  324.630000  324.890000   855.780000  161.470000  ...        31.71   \n",
      "96  320.860000  317.360000   820.660000  159.690000  ...         8.58   \n",
      "97  306.350000  298.280000   742.230000  150.770000  ...         8.75   \n",
      "98  486.400000  491.610000  1450.500000  254.700000  ...        19.38   \n",
      "99  398.516061  415.789899  1132.656061  205.911919  ...        22.42   \n",
      "\n",
      "    K (kg/ha)  Ca (meq/100g)  Mg (meq/100g)  S (ppm)  Fe (ppm)  Mn (ppm)  \\\n",
      "0      444.00       6.140000           2.32    11.21      3.08     14.10   \n",
      "1      372.00       5.980000           0.50    12.93     47.74     37.63   \n",
      "2      132.00       3.150000           2.49     5.17     14.96     44.53   \n",
      "3      221.76       3.400000           1.90    11.59      6.38     10.62   \n",
      "4      234.08       6.600000           5.20    34.10     14.08      3.56   \n",
      "..        ...            ...            ...      ...       ...       ...   \n",
      "95     582.00      13.420652          15.00     8.60      6.27      5.39   \n",
      "96     396.00      13.420652           4.00     1.90      1.18      1.40   \n",
      "97     718.20      33.500000          14.30    11.04      3.70     16.56   \n",
      "98     217.80       6.800000           5.80    48.11      1.84      7.29   \n",
      "99     197.12       5.810000           1.63     7.45     41.17     48.71   \n",
      "\n",
      "    Cu (ppm)  Zn (ppm)  B (ppm)  \n",
      "0       2.23      0.84     1.22  \n",
      "1       3.28      6.79     1.13  \n",
      "2       1.22      1.21     0.98  \n",
      "3       1.77      0.99     0.27  \n",
      "4       1.56      0.40     0.77  \n",
      "..       ...       ...      ...  \n",
      "95      1.27      0.73     0.26  \n",
      "96      1.00      0.75     0.37  \n",
      "97      2.09      1.48     0.63  \n",
      "98      1.82      1.31     0.15  \n",
      "99      2.47      2.65     0.97  \n",
      "\n",
      "[100 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Check for missing values\n",
    "    if df.isnull().values.any():\n",
    "        # Calculate mean for numeric columns only\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "    \n",
    "    # Change non-numeric values to numeric values\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Load your dataset into a pandas DataFrame\n",
    "df = pd.read_csv('values.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "preprocessed_df = preprocess_data(df)\n",
    "print (preprocessed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLSR AND SVMR WITH PCA FOR PREPROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"preprocessed_data.csv\")  \n",
    "\n",
    "\n",
    "X = data[['A(410)', 'B(435)', 'C(460)', 'D(485)', 'E(510)', 'F(535)', 'G(560)',\n",
    "               'H(585)', 'R(610)', 'I(645)', 'S(680)', 'J(705)', 'U(760)',\n",
    "               'V(810)', 'W(860)', 'K(900)', 'L(940)', 'T(730)']]  \n",
    "y = data[['P   (kg/ha)', 'K (kg/ha)', 'Ca (meq/100g)', 'Mg (meq/100g)',\n",
    "             'S (ppm)', 'Fe (ppm)', 'Mn (ppm)', 'Cu (ppm)', 'Zn (ppm)', 'B (ppm)']]  \n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # You can change the strategy if needed\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=10)  # Adjust the number of components as needed\n",
    "X_train_pca = pca.fit_transform(X_train_imputed)\n",
    "X_test_pca = pca.transform(X_test_imputed)\n",
    "\n",
    "# Partial Least Squares Regression (PLSR) with PCA\n",
    "pls_model = PLSRegression(n_components=2)\n",
    "pls_model.fit(X_train_pca, y_train)\n",
    "y_pred_pls = pls_model.predict(X_test_pca)\n",
    "# mse_pls = mean_squared_error(y_test, y_pred_pls)\n",
    "# print(\"PLSR with PCA Mean Squared Error:\", mse_pls)\n",
    "\n",
    "# # Support Vector Machine Regression (SVMR) with PCA\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train_pca)\n",
    "# X_test_scaled = scaler.transform(X_test_pca)\n",
    "# svr_model = SVR(kernel='rbf')\n",
    "# svr_model.fit(X_train_scaled, y_train)\n",
    "# y_pred_svr = svr_model.predict(X_test_scaled)\n",
    "# mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "# print(\"SVMR with PCA Mean Squared Error:\", mse_svr)\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Support Vector Machine Regression (SVMR) with PCA and multiple target variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_pca)\n",
    "X_test_scaled = scaler.transform(X_test_pca)\n",
    "\n",
    "# Initialize SVR\n",
    "svr_model = SVR(kernel='rbf')\n",
    "\n",
    "# Wrap SVR in MultiOutputRegressor\n",
    "multioutput_svr = MultiOutputRegressor(svr_model)\n",
    "\n",
    "# Fit the multi-output SVR model\n",
    "multioutput_svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict for the test set\n",
    "y_pred_svr = multioutput_svr.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "# mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "# print(\"SVMR with PCA Mean Squared Error:\", mse_svr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A(410)', 'B(435)', 'C(460)', 'D(485)', 'E(510)', 'F(535)', 'G(560)',\n",
      "       'H(585)', 'R(610)', 'I(645)', 'S(680)', 'J(705)', 'U(760)', 'V(810)',\n",
      "       'W(860)', 'K(900)', 'L(940)', 'T(730)', 'pH', 'EC  (dS/m)', 'OC (%)',\n",
      "       'P   (kg/ha)', 'K (kg/ha)', 'Ca (meq/100g)', 'Mg (meq/100g)', 'S (ppm)',\n",
      "       'Fe (ppm)', 'Mn (ppm)', 'Cu (ppm)', 'Zn (ppm)', 'B (ppm)'],\n",
      "      dtype='object')\n",
      "PLSR with PCA Mean Squared Error: 4519.7858676866035\n",
      "SVMR with PCA Mean Squared Error: 5958.694726061934\n",
      "PLSR Prediction: [[-4.34041863e+01 -3.29043354e+02  2.44734749e+01 -2.35618863e-01\n",
      "   1.55654687e+01  9.48891971e+01  5.01862280e+01  1.46025755e+01\n",
      "  -1.21114539e+00  1.21095800e+00]]\n",
      "SVMR Prediction: [[ 22.89136681 251.09161838   7.68852505   2.76025689  14.51893539\n",
      "   12.46953651  13.75793649   1.79836452   1.13876407   0.56297738]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"preprocessed_data.csv\")  # Replace with the path to your dataset file\n",
    "\n",
    "# Print the column names to check for mismatches\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "\n",
    "X = data[['A(410)', 'B(435)', 'C(460)', 'D(485)', 'E(510)', 'F(535)', 'G(560)',\n",
    "          'H(585)', 'R(610)', 'I(645)', 'S(680)', 'J(705)', 'U(760)',\n",
    "          'V(810)', 'W(860)', 'K(900)', 'L(940)', 'T(730)']]\n",
    "\n",
    "# Update these column names to match your dataset\n",
    "y = data[['P   (kg/ha)','K (kg/ha)','Ca (meq/100g)','Mg (meq/100g)','S (ppm)','Fe (ppm)','Mn (ppm)','Cu (ppm)','Zn (ppm)','B (ppm)']]\n",
    "\n",
    "# Proceed with the rest of the code as before\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train_imputed)\n",
    "X_test_pca = pca.transform(X_test_imputed)\n",
    "\n",
    "# Partial Least Squares Regression (PLSR) with PCA\n",
    "pls_model = PLSRegression(n_components=2)\n",
    "pls_model.fit(X_train_pca, y_train)\n",
    "y_pred_pls = pls_model.predict(X_test_pca)\n",
    "# mse_pls = mean_squared_error(y_test, y_pred_pls)\n",
    "# print(\"PLSR with PCA Mean Squared Error:\", mse_pls)\n",
    "\n",
    "# Support Vector Machine Regression (SVMR) with PCA and multiple target variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_pca)\n",
    "X_test_scaled = scaler.transform(X_test_pca)\n",
    "\n",
    "svr_model = SVR(kernel='rbf')\n",
    "multioutput_svr = MultiOutputRegressor(svr_model)\n",
    "multioutput_svr.fit(X_train_scaled, y_train)\n",
    "y_pred_svr = multioutput_svr.predict(X_test_scaled)\n",
    "# mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "# print(\"SVMR with PCA Mean Squared Error:\", mse_svr)\n",
    "\n",
    "# Function to predict nutrient values based on user input wavelengths\n",
    "def predict_nutrients(wavelengths):\n",
    "    # Convert the input list to a DataFrame\n",
    "    user_data = pd.DataFrame([wavelengths], columns=X.columns)\n",
    "    \n",
    "    # Handle missing values\n",
    "    user_data_imputed = imputer.transform(user_data)\n",
    "    \n",
    "    # Apply PCA\n",
    "    user_data_pca = pca.transform(user_data_imputed)\n",
    "    \n",
    "    # Scale the data\n",
    "    user_data_scaled = scaler.transform(user_data_pca)\n",
    "    \n",
    "    # Predict using the trained PLS model\n",
    "    pls_prediction = pls_model.predict(user_data_pca)\n",
    "    \n",
    "    # Predict using the trained SVM model\n",
    "    svr_prediction = multioutput_svr.predict(user_data_scaled)\n",
    "    \n",
    "    return pls_prediction, svr_prediction\n",
    "\n",
    "\n",
    "def get_user_wavelengths():\n",
    "    wavelengths = []\n",
    "    for i in range(18):\n",
    "        while True:\n",
    "            try:\n",
    "                value = float(input(f\"Enter value for wavelength {i+1}: \"))\n",
    "                wavelengths.append(value)\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a numerical value.\")\n",
    "    return wavelengths\n",
    "\n",
    "# Get user input\n",
    "user_wavelengths = get_user_wavelengths()\n",
    "\n",
    "# Predict nutrient values\n",
    "pls_pred, svr_pred = predict_nutrients(user_wavelengths)\n",
    "\n",
    "print(\"PLSR Prediction:\", pls_pred)\n",
    "print(\"SVMR Prediction:\", svr_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLS-ANN-PLS for dimensionality reduction followed by ANN for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A(410)', 'B(435)', 'C(460)', 'D(485)', 'E(510)', 'F(535)', 'G(560)',\n",
      "       'H(585)', 'R(610)', 'I(645)', 'S(680)', 'J(705)', 'U(760)', 'V(810)',\n",
      "       'W(860)', 'K(900)', 'L(940)', 'T(730)', 'pH', 'EC  (dS/m)', 'OC (%)',\n",
      "       'P   (kg/ha)', 'K (kg/ha)', 'Ca (meq/100g)', 'Mg (meq/100g)', 'S (ppm)',\n",
      "       'Fe (ppm)', 'Mn (ppm)', 'Cu (ppm)', 'Zn (ppm)', 'B (ppm)'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ruchika Venkat\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ruchika Venkat\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ruchika Venkat\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ruchika Venkat\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ruchika Venkat\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ruchika Venkat\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ruchika Venkat\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLS + MLP Mean Squared Error: 5637.375657240275\n",
      "\n",
      "MLP Prediction:\n",
      "K (kg/ha): 25495.59\n",
      "Ca (meq/100g): 10449.76\n",
      "Mg (meq/100g): -4496.72\n",
      "S (ppm): -268.63\n",
      "Fe (ppm): 80163.98\n",
      "Mn (ppm): 32659.99\n",
      "Cu (ppm): 804.57\n",
      "Zn (ppm): -791.55\n",
      "B (ppm): -41.22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"preprocessed_data.csv\")  # Replace with the path to your dataset file\n",
    "\n",
    "# Print the column names to check for mismatches\n",
    "print(data.columns)\n",
    "\n",
    "# Update these column names to match the actual column names in your dataset\n",
    "feature_columns = ['A(410)', 'B(435)', 'C(460)', 'D(485)', 'E(510)', 'F(535)', 'G(560)',\n",
    "                   'H(585)', 'R(610)', 'I(645)', 'S(680)', 'J(705)', 'U(760)',\n",
    "                   'V(810)', 'W(860)', 'K(900)', 'L(940)', 'T(730)']\n",
    "\n",
    "target_columns = ['K (kg/ha)', 'Ca (meq/100g)', 'Mg (meq/100g)',\n",
    "                  'S (ppm)', 'Fe (ppm)', 'Mn (ppm)', 'Cu (ppm)', 'Zn (ppm)', 'B (ppm)']\n",
    "\n",
    "# Ensure these columns exist in your dataset\n",
    "missing_features = [col for col in feature_columns if col not in data.columns]\n",
    "missing_targets = [col for col in target_columns if col not in data.columns]\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"Feature columns missing from dataset: {missing_features}\")\n",
    "\n",
    "if missing_targets:\n",
    "    print(f\"Target columns missing from dataset: {missing_targets}\")\n",
    "\n",
    "# Separate features (X) and target variables (y)\n",
    "X = data[feature_columns]\n",
    "y = data[target_columns]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Apply PLS for dimensionality reduction\n",
    "pls = PLSRegression(n_components=10)\n",
    "X_train_pls = pls.fit_transform(X_train_imputed, y_train)[0]\n",
    "X_test_pls = pls.transform(X_test_imputed)\n",
    "\n",
    "# Train Multilayer Perceptron (MLP) model for multiple target variables\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=500, random_state=42)\n",
    "\n",
    "# Wrap MLP in MultiOutputRegressor to handle multiple outputs\n",
    "multioutput_mlp = MultiOutputRegressor(mlp)\n",
    "\n",
    "# Fit the MLP model\n",
    "multioutput_mlp.fit(X_train_pls, y_train)\n",
    "\n",
    "# Predict for the test set\n",
    "y_pred_mlp = multioutput_mlp.predict(X_test_pls)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(\"PLS + MLP Mean Squared Error:\", mse_mlp)\n",
    "\n",
    "# Function to predict nutrient values based on user input wavelengths\n",
    "def predict_nutrients(wavelengths):\n",
    "    # Convert the input list to a DataFrame\n",
    "    user_data = pd.DataFrame([wavelengths], columns=feature_columns)\n",
    "    \n",
    "    # Handle missing values\n",
    "    user_data_imputed = imputer.transform(user_data)\n",
    "    \n",
    "    # Apply PLS\n",
    "    user_data_pls = pls.transform(user_data_imputed)\n",
    "    \n",
    "    # Predict using the trained MLP model\n",
    "    mlp_prediction = multioutput_mlp.predict(user_data_pls)\n",
    "    \n",
    "    return mlp_prediction\n",
    "\n",
    "# Function to get user input for wavelengths\n",
    "def get_user_wavelengths():\n",
    "    wavelengths = []\n",
    "    for i in range(18):\n",
    "        while True:\n",
    "            try:\n",
    "                value = float(input(f\"Enter value for wavelength {i+1}: \"))\n",
    "                wavelengths.append(value)\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a numerical value.\")\n",
    "    return wavelengths\n",
    "\n",
    "# Get user input\n",
    "user_wavelengths = get_user_wavelengths()\n",
    "\n",
    "# Predict nutrient values\n",
    "mlp_pred = predict_nutrients(user_wavelengths)\n",
    "\n",
    "# Print the predictions with labels\n",
    "nutrients = ['K (kg/ha)', 'Ca (meq/100g)', 'Mg (meq/100g)', 'S (ppm)', 'Fe (ppm)', 'Mn (ppm)', 'Cu (ppm)', 'Zn (ppm)', 'B (ppm)']\n",
    "\n",
    "print(\"\\nMLP Prediction:\")\n",
    "for nutrient, value in zip(nutrients, mlp_pred[0]):\n",
    "    print(f\"{nutrient}: {value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBRT-GRADIENT BOOSTING TREE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBRT Mean Squared Error: 7165.527231836269\n",
      "\n",
      "GBRT Prediction:\n",
      "K (kg/ha): 536.31\n",
      "Ca (meq/100g): 34.26\n",
      "Mg (meq/100g): 3.67\n",
      "S (ppm): 45.51\n",
      "Fe (ppm): 71.07\n",
      "Mn (ppm): 37.16\n",
      "Cu (ppm): 6.44\n",
      "Zn (ppm): 1.97\n",
      "B (ppm): 0.72\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"preprocessed_data.csv\")  # Replace with the path to your dataset file\n",
    "\n",
    "# Define feature and target columns (make sure these columns exist in your dataset)\n",
    "feature_columns = ['A(410)', 'B(435)', 'C(460)', 'D(485)', 'E(510)', 'F(535)', 'G(560)',\n",
    "                   'H(585)', 'R(610)', 'I(645)', 'S(680)', 'J(705)', 'U(760)',\n",
    "                   'V(810)', 'W(860)', 'K(900)', 'L(940)', 'T(730)']\n",
    "target_columns = ['K (kg/ha)', 'Ca (meq/100g)', 'Mg (meq/100g)',\n",
    "                  'S (ppm)', 'Fe (ppm)', 'Mn (ppm)', 'Cu (ppm)', 'Zn (ppm)', 'B (ppm)']\n",
    "\n",
    "# Check if all required columns are present in the dataset\n",
    "missing_features = [col for col in feature_columns if col not in data.columns]\n",
    "missing_targets = [col for col in target_columns if col not in data.columns]\n",
    "\n",
    "if missing_features:\n",
    "    raise ValueError(f\"Missing feature columns: {missing_features}\")\n",
    "\n",
    "if missing_targets:\n",
    "    raise ValueError(f\"Missing target columns: {missing_targets}\")\n",
    "\n",
    "# Separate features (X) and target variables (y)\n",
    "X = data[feature_columns]\n",
    "y = data[target_columns]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Train Gradient Boosting Regression Trees (GBRT) model for multiple target variables\n",
    "gbrt = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Wrap GBRT in MultiOutputRegressor to handle multiple outputs\n",
    "multioutput_gbrt = MultiOutputRegressor(gbrt)\n",
    "\n",
    "# Fit the GBRT model\n",
    "multioutput_gbrt.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict for the test set\n",
    "y_pred_gbrt = multioutput_gbrt.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_gbrt = mean_squared_error(y_test, y_pred_gbrt)\n",
    "print(\"GBRT Mean Squared Error:\", mse_gbrt)\n",
    "\n",
    "# Function to predict nutrient values based on user input wavelengths\n",
    "def predict_nutrients(wavelengths):\n",
    "    # Convert the input list to a DataFrame\n",
    "    user_data = pd.DataFrame([wavelengths], columns=feature_columns)\n",
    "    \n",
    "    # Handle missing values\n",
    "    user_data_imputed = imputer.transform(user_data)\n",
    "    \n",
    "    # Scale the data\n",
    "    user_data_scaled = scaler.transform(user_data_imputed)\n",
    "    \n",
    "    # Predict using the trained GBRT model\n",
    "    gbrt_prediction = multioutput_gbrt.predict(user_data_scaled)\n",
    "    \n",
    "    return gbrt_prediction\n",
    "\n",
    "# Function to get user input for wavelengths\n",
    "def get_user_wavelengths():\n",
    "    wavelengths = []\n",
    "    for i in range(len(feature_columns)):\n",
    "        while True:\n",
    "            try:\n",
    "                value = float(input(f\"Enter value for {feature_columns[i]}: \"))\n",
    "                wavelengths.append(value)\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a numerical value.\")\n",
    "    return wavelengths\n",
    "\n",
    "# Get user input\n",
    "user_wavelengths = get_user_wavelengths()\n",
    "\n",
    "# Predict nutrient values\n",
    "gbrt_pred = predict_nutrients(user_wavelengths)\n",
    "\n",
    "# Print the predictions with labels\n",
    "print(\"\\nGBRT Prediction:\")\n",
    "for nutrient, value in zip(target_columns, gbrt_pred[0]):\n",
    "    print(f\"{nutrient}: {value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Mean Squared Error: 5409.085520762519\n",
      "GBRT Mean Squared Error: 7165.527231836269\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of the target values as a simple baseline\n",
    "baseline_prediction = y_train.mean(axis=0)\n",
    "\n",
    "# Predict the baseline for the test set\n",
    "baseline_predictions = [baseline_prediction] * len(y_test)\n",
    "\n",
    "\n",
    "baseline_mse = mean_squared_error(y_test, baseline_predictions)\n",
    "print(\"Baseline Mean Squared Error:\", baseline_mse)\n",
    "\n",
    "\n",
    "print(\"GBRT Mean Squared Error:\", mse_gbrt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
